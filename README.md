# Amazon Electronics Reviews â€” Dataset-level Analysis

This project analyzes the **Amazon Reviews (2018) â€” Electronics** dataset  
([original source](https://nijianmo.github.io/amazon/index.html)).  

We explore ratings, review helpfulness, sentiment, and topics at the **dataset level**.  
Outputs include pros/cons sentences, topic models, and semantic search index.  
Large raw data and models are stored locally in `data/` (not committed to Git).

---

## ğŸ“‚ Repository Structure

amazon-reviews-analysis/
â”œâ”€ notebooks/
â”‚ â””â”€ Amazon_Reviews_Analysis_2018.ipynb # main Colab notebook
â”œâ”€ data/ # raw data (large CSVs, FAISS index, models) â€” not pushed
â”‚ â””â”€ electronics_small.csv # (example; keep in Drive, not GitHub)
â”œâ”€ outputs/ # small results safe to commit
â”‚ â”œâ”€ top_positive_sentences.csv
â”‚ â”œâ”€ top_negative_sentences.csv
â”‚ â”œâ”€ lsa_topics.json
â”‚ â”œâ”€ dataset_summary.json
â”‚ â”œâ”€ monthly_review_counts.csv
â”‚ â””â”€ monthly_avg_rating.csv
â”œâ”€ README.md
â”œâ”€ LICENSE
â””â”€ .gitignore


---

## ğŸš€ Quickstart (Google Colab)

1. Open `notebooks/amazon_reviews_colab.ipynb` in [Google Colab](https://colab.research.google.com/).
2. Mount Google Drive:
   ```python
   from google.colab import drive
   drive.mount('/content/drive')
   DATA_PATH = "/content/drive/My Drive/Amazon-Analysis/electronics_small.csv"


Run cells sequentially:

EDA: ratings distribution, helpful votes, time trends

Review-level features: lengths, helpfulness correlation

Sentence-level pros/cons extraction (VADER-based)

Topic modeling (TF-IDF + LSA)

Semantic search demo (embeddings + FAISS)

Outputs (CSV/JSON) are saved under outputs/.

ğŸ“Š Features Implemented

Exploratory Data Analysis (EDA): ratings, votes, time trends

Sentiment analysis: VADER polarity vs. ratings

Sentence-level pros/cons extraction (top positive & negative sentences)

Topic discovery with TF-IDF + Latent Semantic Analysis (LSA)

Semantic search demo (Sentence-BERT + FAISS)

ğŸ“¦ Data & Models

Not in GitHub (large files):

electronics_small.csv (3M reviews)

reviews_index.faiss (semantic search index)

tfidf_30000.joblib, lgb_helpful_model.pkl (model artifacts)

ğŸ‘‰ Keep these in data/ locally or in Google Drive.
To recreate them, run the notebookâ€™s relevant cells.

ğŸ› ï¸ How to Run Locally

Clone this repo and install requirements:

git clone https://github.com/YOUR_USERNAME/amazon-reviews-analysis.git
cd amazon-reviews-analysis
pip install -r requirements.txt


Recommended minimal requirements.txt:

pandas
numpy
matplotlib
seaborn
plotly
scikit-learn
vaderSentiment
sentence-transformers
faiss-cpu
tqdm

ğŸ“¤ Push to GitHub (step-by-step)
# initialize repo (first time only)
git init
git add .
git commit -m "Initial commit: Amazon reviews analysis"

# connect to GitHub repo
git branch -M main
git remote add origin git@github.com:YOUR_USERNAME/amazon-reviews-analysis.git   # SSH
# or: git remote add origin https://github.com/YOUR_USERNAME/amazon-reviews-analysis.git   # HTTPS

# push
git push -u origin main


âš ï¸ Do not push raw CSVs, FAISS indexes, or model binaries â€” theyâ€™re too large.
Keep them in data/ (ignored by .gitignore) or store in Drive/S3.

ğŸ“„ License

MIT License

ğŸ™Œ Acknowledgements

Dataset: Amazon Review Data (2018)

Paper: Justifying recommendations using distantly-labeled reviews and fined-grained aspects
Jianmo Ni, Jiacheng Li, Julian McAuley (EMNLP, 2019)


---

âœ¨ Copy this into your `README.md` file and youâ€™re good to go.  

Do you also want me to give you a **ready `requirements.txt`** content (so you can copyâ€“paste that too)?
